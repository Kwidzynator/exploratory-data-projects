{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a77807f92f26ee",
   "metadata": {},
   "source": [
    "Natan Warelich 318159\n",
    "\n",
    "\n",
    "# Wprowadzenie\n",
    "Raport jest oparty na zbiorze win białych. Wykorzystany model do klasyfikacji to random forest, nastomiast do szacowania Extreme Gradient Boosting natomiast do podziału na grupy zastosowany będzie DBSCAN.\n",
    "\n",
    "# Eksploracyjna analiza danych\n",
    "\n",
    "## Weryfikacja danych\n",
    "\n",
    "Zacznijmy od wczytania danych. Standardowo wykorzystano ku temu bibliotekę pandas."
   ]
  },
  {
   "cell_type": "code",
   "id": "fbc121e30a2defb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T14:05:29.748492Z",
     "start_time": "2025-06-07T14:05:29.740330Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"white_wine.csv\", sep=\";\")"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Następnie wszystkie dane zostały sprawdzone czy mają prawidłowy typ danych. I okazało się że wszystkie zmienne są zdefiniowane jako object, przez zapis zmiennych przecinkowych przy zastosowania przecinka zamiast kropki. Dodatkowo niektóre dane mniejsze od zera zostały zapisane jako np ,4 co powodowało dodatkowe problemy. Przed edycją dane zostały sprawdzone pod względem wykrycia braków i żadne nie zostały wykryte. W celu zwalczenia tego zastosowana została poniższa funkcja",
   "id": "23fcb68166178525"
  },
  {
   "cell_type": "code",
   "id": "1eb05adf0c52c0a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T14:05:32.590165Z",
     "start_time": "2025-06-07T14:05:32.552866Z"
    }
   },
   "source": [
    "for col in data.columns[:-1]:\n",
    "    data[col] = data[col].astype(str)\n",
    "    data[col] = data[col].apply(lambda x: \"0\" + x if x.startswith(\",\") else x)\n",
    "\n",
    "    data[col] = data[col].str.replace(',', '.', regex=False)\n",
    "    data[col] = data[col].astype(float).round(3)\n"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "id": "e8f18a48b91ec741",
   "metadata": {},
   "source": [
    "Sprawdźmy teraz dane pod względem:\n",
    "- duplikatów\n",
    "- obserwacji odstających\n",
    "- brak wartości niezgodnych z założeniami\n",
    "\n",
    "Zacznijmy od braku duplikatów\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "efcd95c07e85621",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T14:05:32.956280Z",
     "start_time": "2025-06-07T14:05:32.952098Z"
    }
   },
   "source": [
    "print(data.duplicated().sum())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "cell_type": "markdown",
   "id": "48f563c20690cc29",
   "metadata": {},
   "source": [
    "Jak widzimy mamy, aż 645 duplikatów, jest to spora liczba warto będzie sprawdzić, przy eksploracji danych różnicę między modelami z i bez tych danych.\n",
    "\n",
    "Zobaczmy teraz czy wszystkie dane są zgodne z założeniami. Zacznijmy od danych ujemnych."
   ]
  },
  {
   "cell_type": "code",
   "id": "67d3dc2f1d8bc10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T14:05:33.521812Z",
     "start_time": "2025-06-07T14:05:33.515926Z"
    }
   },
   "source": [
    "print(data[data <= 0].sum())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixedacidity          0.0\n",
      "volatileacidity       0.0\n",
      "citricacid            0.0\n",
      "residualsugar         0.0\n",
      "chlorides             0.0\n",
      "freesulfurdioxide     0.0\n",
      "totalsulfurdioxide    0.0\n",
      "density               0.0\n",
      "pH                    0.0\n",
      "sulphates             0.0\n",
      "alcohol               0.0\n",
      "quality               0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "cell_type": "markdown",
   "id": "70c1849e4d4a65f7",
   "metadata": {},
   "source": [
    "Dane ujemne nie występują. Sprawdźmy jeszcze czy gdzieś są dane są mało realistyczne między innymi:\n",
    "\n",
    "- Alkohol: zwracamy uwagę na wartości powyżej 20%, które są nietypowe dla białego wina.\n",
    "- pH: typowe wartości dla wina białego mieszczą się w przedziale [3.0, 3.4]. Weryfikujemy, czy nie występują próbki o pH ≤ 2.5 lub pH ≥ 3.9, co może świadczyć o błędzie lub nietypowej próbce.\n",
    "- Lotna kwasowość: zazwyczaj mieści się w przedziale [0.1, 1.5] g/l. Sprawdzamy, czy nie ma wartości ≥ 1.6 g/l, które mogą być podejrzane.\n",
    "- Kwas cytrynowy: występuje zwykle w niewielkich ilościach, dlatego zwracamy uwagę na wartości ≥ 1.1 g/l.\n",
    "- Cukier: ze względu na dużą zmienność między różnymi stylami wina, nie definiujemy tu wartości nietypowych.\n",
    "- Chlorki: w białych winach mogą występować do około 0.6 g/l; sprawdzamy, czy nie pojawiają się wartości ≥ 1.0 g/l.\n",
    "- Wolny i całkowity dwutlenek siarki: odstające wartości mogą wpływać na zdrowotność i jakość wina, ale nie zmieniają jego klasyfikacji jako białego wina.\n",
    "- Gęstość: podobnie jak dwutlenek siarki, nie ma wartości dyskwalifikujących próbkę jako białe wino."
   ]
  },
  {
   "cell_type": "code",
   "id": "8545b58543ecf4f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T14:05:34.802811Z",
     "start_time": "2025-06-07T14:05:34.797193Z"
    }
   },
   "source": [
    "print(data['alcohol'].where(data['alcohol'] >= 20).count())\n",
    "print(data['pH'].where((data['pH'] >= 3.9) | (data['pH'] <= 2.5)).count())\n",
    "print(data['volatileacidity'].where((data['volatileacidity'] >= 1.6)).count())\n",
    "print(data['citricacid'].where((data['citricacid'] >= 1.1)).count())\n",
    "print(data['sulphates'].where((data['sulphates'] >= 1.0)).count())\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "cell_type": "markdown",
   "id": "bcaf6d75c82bb2f2",
   "metadata": {},
   "source": [
    "Mamy jedynie dwa dane z chlorkach które można określić jako potencjalnie odstające, jednakże nie należy wydawać przedwcześnie osądów.\n",
    "\n",
    "\n",
    "\n",
    "## Rozkład jakości win\n",
    "Rozkład jakości win prezentuje się następująco:\n",
    "\n",
    "![Wykres rozkładu jakości wina](rozklad_jakosci_wina.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5553cfbf421477bc",
   "metadata": {},
   "source": "Na podstawie wykresu można zauważyć, że rozkład zmiennej quality przypomina rozkład normalny w zakresie ocen od 1 do 7. Najwięcej jest win o jakości 4, natomiast najmniej o jakości 1 i 7. Jednakże widać, iż są to znikome wartości w związku z czym warto będzie je połaczyć z kategoriami obok. Taki rozkład może być korzystny, jeśli chcielibyśmy zastosować np. regresję liniową, choć należy pamiętać, że quality to zmienna dyskretna i porządkowa, więc model ten powinien być używany ostrożnie."
  },
  {
   "cell_type": "markdown",
   "id": "4359a3463bf3be34",
   "metadata": {},
   "source": [
    "## Macierz korelacji i wykresy rozrzutu\n",
    "Macierz korelacji liniowej Pearsona została przedstawiona na rysunku poniżej"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![macierz korelacji](macierz_korelacji.png)",
   "id": "2222710cf9d3aecc"
  },
  {
   "cell_type": "markdown",
   "id": "601f59fc4e4b1c17",
   "metadata": {},
   "source": [
    "Na podstawie macierzy korelacji zauważalny jest praktycznie zerowy związek zmiennych free sulfur dioxide oraz citric acid z jakością wina. Najsilniejszą dodatnią korelację z jakością obserwujemy dla zawartości alkoholu, co sugeruje, że wyższy poziom alkoholu może być czynnikiem wpływającym pozytywnie na ocenę wina.\n",
    "\n",
    "Warto również zwrócić uwagę na wyraźne ujemne korelacje pomiędzy alkoholem a innymi cechami, szczególnie z gęstością – co jest zgodne z fizyczną zależnością: im więcej alkoholu, tym niższa gęstość cieczy. Z kolei zależność między zawartością cukru a gęstością jest dodatnia – co także jest intuicyjne, ponieważ cukier zwiększa masę roztworu.\n",
    "\n",
    "Aby lepiej zrozumieć te relacje, warto przeanalizować wykresy rozrzutu dla zmiennych wykazujących najsilniejszą korelację dodatnią i ujemną z jakością wina oraz z alkoholem."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![alkohol a wino](alkohol_a_wino.png)",
   "id": "920a9ef5e12bb478"
  },
  {
   "cell_type": "markdown",
   "id": "443e4d83fba018f6",
   "metadata": {},
   "source": [
    "Choć zawartość alkoholu wykazuje ogólną dodatnią korelację z jakością wina, nie ma tu jednej \"złotej reguły\". Z wykresu rozrzutu wynika, że wśród win ocenionych najwyżej, większość ma zawartość alkoholu w przedziale 12–13%, co może wskazywać na preferencję dla takiego balansu."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![alkohol a gęstość](alkohol_a_gestosc.png)",
   "id": "828047bd3f447dbb"
  },
  {
   "cell_type": "markdown",
   "id": "79f6dac6bb1f6f7",
   "metadata": {},
   "source": [
    "Zależność pomiędzy alkoholem a gęstością potwierdza założenia z macierzy korelacji – im wyższy procent alkoholu, tym niższa gęstość cieczy. Na wykresie zauważalna jest jedna wartość odstająca o stosunkowo wysokiej gęstości mimo stosunkowo dużej zawartości alkoholu."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![cukier a gestosc](cukier_a_gestosc.png)",
   "id": "5db66f73990ed7dd"
  },
  {
   "cell_type": "markdown",
   "id": "d9024cee228869e5",
   "metadata": {},
   "source": [
    "Analiza tej obserwacji potwierdza przypuszczenie: wartość odstająca charakteryzuje się znaczną zawartością cukru resztkowego. Zgodnie z zasadami fizyki i chemii, większa ilość cukru zwiększa gęstość roztworu, co tłumaczy odchylenie od ogólnego trendu."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model klasyfikacyjny\n",
    "## Model i parametry\n",
    "Szkolony model to Random Forest, skorzystamy z następujących ustawień parametrów:\n",
    "- test_size = 0.3\n",
    "- random_state = 318159\n",
    "- n_estimators = 300\n",
    "## Bazowy model\n",
    "Statystyki bazowego modelu prezentują się następująco."
   ],
   "id": "c0a8611917936153"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T14:45:55.377476Z",
     "start_time": "2025-06-07T14:45:54.175313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=318159)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=300, random_state=318159)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "within_1 = np.abs(y_test - y_pred) <= 1\n",
    "acc_within_1 = np.mean(within_1)\n",
    "\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Accuracy with tolerance ±1:\", acc_within_1)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, zero_division=0))"
   ],
   "id": "9b614fb1abfa1ab2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6963151207115629\n",
      "Accuracy with tolerance ±1: 0.9720457433290979\n",
      "Mean Absolute Error (MAE): 0.3341804320203304\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.89      0.29      0.43        28\n",
      "           3       0.67      0.71      0.69       252\n",
      "           4       0.68      0.75      0.72       357\n",
      "           5       0.75      0.65      0.70       124\n",
      "           6       1.00      0.46      0.63        24\n",
      "           7       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.70       787\n",
      "   macro avg       0.57      0.41      0.45       787\n",
      "weighted avg       0.71      0.70      0.69       787\n",
      "\n"
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Tak jak przypuszczaliśmy bazowy model nie wykrywa 1 i 7 w związku z czym połączmy te zmienne z kategoriami obok. Natomiast bazowy model ma trafność 65% co nie należyt do najlepszych wyników. Jednakże warto zwrócić uwagę na trafność z tolerancją ±1. Jest ona bardzo wysoka co się zgadza gdyż MAE wynosi ok 0.33. Sprawdźmy rezultaty dla połączonych danych, oraz pozbądźmy się tych danych których korelacja wskazuje na nikły wpływ na miarę jakości modelu, a dokładniej: citricacid, freesulfurdioxide, sulphates.",
   "id": "efe72a75c271a683"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T14:48:32.128620Z",
     "start_time": "2025-06-07T14:48:31.216326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "X_filtered = X.drop(columns=[\"citricacid\", \"freesulfurdioxide\", \"sulphates\"])\n",
    "y_grouped = y.replace({1: 2, 7: 6})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_filtered, y_grouped, test_size=0.2, random_state=318159)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=300, random_state=318159)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "within_1 = np.abs(y_test - y_pred) <= 1\n",
    "acc_within_1 = np.mean(within_1)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Accuracy with tolerance ±1:\", acc_within_1)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, zero_division=0))"
   ],
   "id": "9b47030c65b7857c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6759847522236341\n",
      "Accuracy with tolerance ±1: 0.9733163913595934\n",
      "Mean Absolute Error (MAE): 0.3519695044472681\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           2       0.75      0.21      0.32        29\n",
      "           3       0.68      0.69      0.69       252\n",
      "           4       0.67      0.73      0.70       357\n",
      "           5       0.65      0.65      0.65       124\n",
      "           6       0.92      0.44      0.59        25\n",
      "\n",
      "    accuracy                           0.68       787\n",
      "   macro avg       0.73      0.54      0.59       787\n",
      "weighted avg       0.68      0.68      0.67       787\n",
      "\n"
     ]
    }
   ],
   "execution_count": 94
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Połączenie co raczej jest oczywiste tylko obniżyło nam notowania. Jednakże, nasza próbka danych jest tak niska, że i tak warto je zachować. Sprawdźmy więc teraz model wykluczając duplikaty a następnie outlinery.",
   "id": "92095fdbadffb613"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T15:56:55.339613Z",
     "start_time": "2025-06-07T15:56:54.019933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_cpy = data.copy()\n",
    "data_cpy = data_cpy.drop_duplicates()\n",
    "\n",
    "X = data_cpy.iloc[:, :-1]\n",
    "y = data_cpy.iloc[:, -1]\n",
    "\n",
    "y_grouped = y.replace({1: 2, 7: 6})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_grouped, test_size=0.2, random_state=318159)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=300, random_state=318159)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "within_1 = np.abs(y_test - y_pred) <= 1\n",
    "acc_within_1 = np.mean(within_1)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Accuracy with tolerance ±1:\", acc_within_1)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, zero_division=0))"
   ],
   "id": "964e48b7b183227",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5486322188449848\n",
      "Accuracy with tolerance ±1: 0.9513677811550152\n",
      "Mean Absolute Error (MAE): 0.5015197568389058\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           2       0.80      0.11      0.19        37\n",
      "           3       0.57      0.59      0.58       185\n",
      "           4       0.54      0.72      0.62       288\n",
      "           5       0.54      0.29      0.38       126\n",
      "           6       0.50      0.09      0.15        22\n",
      "\n",
      "    accuracy                           0.55       658\n",
      "   macro avg       0.59      0.36      0.38       658\n",
      "weighted avg       0.56      0.55      0.52       658\n",
      "\n"
     ]
    }
   ],
   "execution_count": 121
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Pozbycie się duplikatów znacząco pogorszyło nasz model w związku z czym dalsze prace będą uwzględniałe te dane. Sprawdźmy teraz sytuację bez outlinerów.",
   "id": "3cca8c39068eedc7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T14:49:20.070002Z",
     "start_time": "2025-06-07T14:49:19.190153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_cpy = data.copy()\n",
    "\n",
    "X = data_cpy.iloc[:, :-1]\n",
    "y = data_cpy.iloc[:, -1]\n",
    "\n",
    "y_grouped = y.replace({1: 2, 7: 6})\n",
    "\n",
    "Q1 = X.quantile(0.25)\n",
    "Q3 = X.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "mask = ~((X < (Q1 - 1.5 * IQR)) | (X > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "X_no_outliers = X[mask]\n",
    "y_no_outliers = y_grouped[mask]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_no_outliers, y_no_outliers, test_size=0.3, random_state=318159)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=300, random_state=318159)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "within_1 = np.abs(y_test - y_pred) <= 1\n",
    "acc_within_1 = np.mean(within_1)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Accuracy with tolerance ±1:\", acc_within_1)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, zero_division=0))"
   ],
   "id": "52f5308f3381a79f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6793422404933196\n",
      "Accuracy with tolerance ±1: 0.9681397738951696\n",
      "Mean Absolute Error (MAE): 0.35354573484069884\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           2       1.00      0.26      0.41        23\n",
      "           3       0.72      0.66      0.68       276\n",
      "           4       0.64      0.82      0.72       445\n",
      "           5       0.73      0.50      0.60       195\n",
      "           6       0.85      0.32      0.47        34\n",
      "\n",
      "    accuracy                           0.68       973\n",
      "   macro avg       0.79      0.51      0.58       973\n",
      "weighted avg       0.70      0.68      0.67       973\n",
      "\n"
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Brak outlinerów wreszcie pozwolił nam uzyskać lepsze wyniki. Widzimy również lekkie przecuczenie dla 1-2. Jednakże sprawdzenie na innych parametrach powodowało obniżenie recall oraz f1-score. Co ciekawe trafność ogólnego modelu wzrosła, jednakże MAE oraz dla tolerancji spadła. Teraz spróbujmy polepszyć jakość tego modelu poprzez zastosowanie danych walidacyjnych.",
   "id": "5d2f8e035775b013"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T14:50:31.056461Z",
     "start_time": "2025-06-07T14:50:30.252190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "data_cpy = data.copy()\n",
    "\n",
    "X = data_cpy.iloc[:, :-1]\n",
    "y = data_cpy.iloc[:, -1]\n",
    "\n",
    "y_grouped = y.replace({1: 2, 7: 6})\n",
    "\n",
    "Q1 = X.quantile(0.25)\n",
    "Q3 = X.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "mask = ~((X < (Q1 - 1.5 * IQR)) | (X > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "X_no_outliers = X[mask]\n",
    "y_no_outliers = y_grouped[mask]\n",
    "\n",
    "# Podział na trening (60%), walidację (20%) i test (20%) ze stratifikacją\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X_no_outliers, y_no_outliers, test_size=0.4, random_state=318159, stratify=y_no_outliers\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=318159, stratify=y_temp\n",
    ")\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=300, random_state=318159)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predykcje na zbiorze walidacyjnym\n",
    "y_val_pred = clf.predict(X_val)\n",
    "\n",
    "val_acc = accuracy_score(y_val, y_val_pred)\n",
    "val_acc_within_1 = np.mean(np.abs(y_val - y_val_pred) <= 1)\n",
    "val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "\n",
    "print(\"Validation Accuracy:\", val_acc)\n",
    "print(\"Validation Accuracy with tolerance ±1:\", val_acc_within_1)\n",
    "print(\"Validation MAE:\", val_mae)\n",
    "print(\"Validation Classification Report:\\n\", classification_report(y_val, y_val_pred, zero_division=0))\n",
    "\n",
    "\n",
    "# Predykcje na zbiorze testowym\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "test_acc_within_1 = np.mean(np.abs(y_test - y_test_pred) <= 1)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"\\nTest Accuracy:\", test_acc)\n",
    "print(\"Test Accuracy with tolerance ±1:\", test_acc_within_1)\n",
    "print(\"Test MAE:\", test_mae)\n",
    "print(\"Test Classification Report:\\n\", classification_report(y_test, y_test_pred, zero_division=0))"
   ],
   "id": "994ec0a2b76493ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6178736517719569\n",
      "Validation Accuracy with tolerance ±1: 0.9661016949152542\n",
      "Validation MAE: 0.41602465331278893\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           2       1.00      0.24      0.38        17\n",
      "           3       0.65      0.60      0.62       184\n",
      "           4       0.60      0.72      0.66       298\n",
      "           5       0.59      0.51      0.55       128\n",
      "           6       1.00      0.27      0.43        22\n",
      "\n",
      "    accuracy                           0.62       649\n",
      "   macro avg       0.77      0.47      0.53       649\n",
      "weighted avg       0.64      0.62      0.61       649\n",
      "\n",
      "\n",
      "Test Accuracy: 0.6456086286594761\n",
      "Test Accuracy with tolerance ±1: 0.9661016949152542\n",
      "Test MAE: 0.3882896764252696\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           2       0.60      0.19      0.29        16\n",
      "           3       0.69      0.66      0.68       185\n",
      "           4       0.62      0.76      0.68       297\n",
      "           5       0.66      0.45      0.54       128\n",
      "           6       0.80      0.35      0.48        23\n",
      "\n",
      "    accuracy                           0.65       649\n",
      "   macro avg       0.67      0.48      0.53       649\n",
      "weighted avg       0.65      0.65      0.64       649\n",
      "\n"
     ]
    }
   ],
   "execution_count": 96
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Krzywa roc\n",
    "Dane walidacyjne pogorszyły nasz model. W związku z czym sprawdziliśmy różne sposoby i otrzymaliśmy najlepszy wynik dla samego wyzbycia się outlinerów. Sprawdźmy więc jak wygląda krzywa roc dla tego modelu."
   ],
   "id": "5fe08842f4bb4fe1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![krzywa ROC jakości wina](roc_jakosc_wina.png)",
   "id": "1f21934cbcfc850c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Jak widać najlepiej model znajduje klase 2 a najgorszej klasę 4 która jest najliczniejsza. Co się oczywiście zgadza z naszymi danymi, gdyż uwzględniamy tam recall i precision.",
   "id": "21379ae73a3db5a4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Wpływ danych na budowę modelu\n",
    "W przypadku tego modelu wykres najbardziej wpływowych danych prezentuje się następująco:"
   ],
   "id": "338afa7b4eca1635"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![ważność cech random forest](waznosc_cech_rf.png)",
   "id": "7a0c964abd34309e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Jak widać tak jak współczynniki korelacji podpowiadały, wartość alkohol była najbardziej wpłwowa przy budowie modelu. Co ciekawe jednak gęstość która miała być jedną z bardziej wpływowych wartości w tym modelu została uznana za mało ważną. Oraz wolny dwutlenek siarki który wykazywał zerową korelację, był jedną z ważniejszych cech. Co tłumaczy dlaczego przy pozbyciu się danych z zerową korelacją jakość modelu spadała.",
   "id": "8ecefe375662f689"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "## Podsumowanie\n",
    "Model nieradzi sobie najlepiej z klasyfikacją. Jednakże, w przypadku dania marginesu błędu +/- 1 model ten sprawdza się wyśmienicie co może stanowić rozwiązanie na postawiony problem. Dodatkowo najważniejszymi danymi przy budowie modelu niekoniecznie były te które pierwotnie wskazała korelacja Pearsona."
   ],
   "id": "55b07c97eef7e250"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model Regresyjny\n",
    "## Model i parametry\n",
    "Wykorzystany model to XGBoost z następującymi parametrami:\n",
    "- test_size = 0.3\n",
    "- random_state = 318159\n",
    "- n_estimators = 300"
   ],
   "id": "ff095cc10e7e21de"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Bazowy model\n",
    "Statystyki dla bazowego modelu prezentują się następująco:"
   ],
   "id": "48b51f6544e7a447"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T15:53:03.977474Z",
     "start_time": "2025-06-07T15:53:03.849477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "X = data_cpy.iloc[:, :-1]\n",
    "y = data_cpy.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=318159)\n",
    "\n",
    "model = XGBRegressor(random_state=318159, n_estimators=300, eval_metric='mae')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred_rounded = np.clip(np.round(y_pred), 1, 7).astype(int)\n",
    "\n",
    "accuracy_exact = accuracy_score(y_test, y_pred_rounded)\n",
    "accuracy_within_1 = np.mean(np.abs(y_test - y_pred_rounded) <= 1)\n",
    "mae = mean_absolute_error(y_test, y_pred_rounded)\n",
    "\n",
    "print(f\"Accuracy (dokładna): {accuracy_exact:.4f}\")\n",
    "print(f\"Accuracy z dopuszczalnym odstępstwem ±1: {accuracy_within_1:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")"
   ],
   "id": "fe55ace48b14d11c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (dokładna): 0.6224\n",
      "Accuracy z dopuszczalnym odstępstwem ±1: 0.9594\n",
      "Mean Absolute Error (MAE): 0.4217\n"
     ]
    }
   ],
   "execution_count": 116
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Jak widzimy mamy w bardzo podobną sytuację, stosunkowo niską trafność, jednakże bardzo wysoką z dopuszczalnym błędem 1. Jako, iż wcześniej jedynym rozwiązaniem dającym jakiekolwiek rezultaty było pozbycie się danych odstających zróbmy to też tutaj.\n",
   "id": "480ff44bc130c3e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T16:04:01.005098Z",
     "start_time": "2025-06-07T16:04:00.875974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_cpy = data.copy()\n",
    "\n",
    "X = data_cpy.iloc[:, :-1]\n",
    "y = data_cpy.iloc[:, -1]\n",
    "\n",
    "y_grouped = y.replace({1: 2, 7: 6})\n",
    "\n",
    "Q1 = X.quantile(0.25)\n",
    "Q3 = X.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "mask = ~((X < (Q1 - 1.5 * IQR)) | (X > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "X_no_outliers = X[mask]\n",
    "y_no_outliers = y_grouped[mask]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_no_outliers, y_no_outliers, test_size=0.3, random_state=318159)\n",
    "\n",
    "model = XGBRegressor(random_state=318159, n_estimators=300, eval_metric='mae')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred_rounded = np.clip(np.round(y_pred), 1, 7).astype(int)\n",
    "\n",
    "accuracy_exact = accuracy_score(y_test, y_pred_rounded)\n",
    "accuracy_within_1 = np.mean(np.abs(y_test - y_pred_rounded) <= 1)\n",
    "mae = mean_absolute_error(y_test, y_pred_rounded)\n",
    "\n",
    "print(f\"Accuracy (dokładna): {accuracy_exact:.4f}\")\n",
    "print(f\"Accuracy z dopuszczalnym odstępstwem ±1: {accuracy_within_1:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")"
   ],
   "id": "afd1ad255e32963b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (dokładna): 0.6536\n",
      "Accuracy z dopuszczalnym odstępstwem ±1: 0.9723\n",
      "Mean Absolute Error (MAE): 0.3751\n"
     ]
    }
   ],
   "execution_count": 124
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Jak widać podobnie jak w przypadku klasyfikacji, usunięcie outlinerów dało pozytywne rezultaty. Jednakże jako, iż ten model jest zupełnie inny sprawdzone zostały rezultaty analogicznych podpunktów co w przypadku klasyfikacji, o to rezultaty:\n",
    "- usuniecie zbędnych według korelacji danych: pogorszenie modelu\n",
    "- pozbycie się duplikatów: pogorszenie modelu\n",
    "- dane walidacyjne: pogorszenie modelu"
   ],
   "id": "2841f500a71a0f55"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Wpływ danych na budowę modelu\n",
    "W przypadku tego modelu wykres najbardziej wpływowych danych prezentuje się następująco:\n"
   ],
   "id": "ad72b708d36736f0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![ważność cech xgboost](waznosc_cech_xgb.png)",
   "id": "efcba029408e1977"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Jak widać alkohol który wskazał wykres korelacji okazał się być drugą najmniej wpływową wartością przy budowie modelu. Najważniejszą wartością okazała się stała kwasowość, a następnie cukier. Stanowi to zupełnie inne wnioski, a niżeli te nasunięte przy pracy bezpośrednio z danymi.",
   "id": "9b470b3a28a68296"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Podsumowanie\n",
    "Model XGBoost dla regresji podobnie jak model random forest dla klasyfikacji nie jest najlepszy w przewidywaniu oceny jakości wina, jednakże dla wersji z marginesem błędu daje sobie radę. Jednakże w tym przypadku róznica między danymi wpłwowymi w budowie tego modelu jest znacząca gdyż dwie najbardziej zkorelowane z oceną jakości dane, miały najmniejszy wpływ na budowę modelu.\n",
    "\n",
    "# Podział win na grupy\n",
    "\n",
    "# Model i parametry\n",
    "W celu pogrupowania danych wykorzystany zostanie model K-średnich, z następującymi parametrami:\n",
    "- k = 7\n",
    "- random_state = 318159\n",
    "- n_components = 2\n"
   ],
   "id": "bb3cabc6167788d9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Model z standaryzacją\n",
    "Wykres modelu k-średnich ze standaryzacją prezentuje się następująco:\n",
    "\n",
    "![k-średnich standaryzowane dane](ksrednich_standaryzacja.png)\n",
    "\n"
   ],
   "id": "9e22905a6c420069"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Jak widać w przypadku grupowania metodą K-średnich dla danych poddanych standaryzacji dostajemy zupełnie sprzeczne z rzeczywistością informacje. Na wykresie możemy dostrzeć dużą ilość jedynek oraz dużą ilość siódemek co jest przeciwieństwem od faktycznych danych. Należy jeszcze zobaczyć miarę jakości, aby potwierdzić nasze informacje.",
   "id": "5082b0946c9c534"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Tak jak przypuszczaliśmy model ten wręcz tragicznie przypisuje dane co widać na podstawie wykresu czy też średniej wartości miary sylwetki.\n",
    "Sprawdźmy jak wygląda wykres gdy dane poddamy normalizacji."
   ],
   "id": "2d486e0ce932f180"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Model z normalizacją\n",
    "\n",
    "![k-średnich normalizacja](ksrednich_normalizacja.png)"
   ],
   "id": "212ea0db4d9650be"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Oczywiście model K-Średnich źle dobiera podział na klasy. Można byłoby jeszcze sprawdzić dla mniejszych próbek danych. Z tym że ogólna ilość danych nie jest jakaś wielka, więc jedyne do czego to doprowadzi to do pogorszenia wyników. Zobaczmy jeszcze miarę jakości. zobaczmy jeszcze jak wygląda miara jakości.\n",
   "id": "a58d0d71b4fd2fed"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![wykres miary sylwetki klastrów](miary_sylwetki_klastrow.png)",
   "id": "798e186f60d5089b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Potwierdza to nasze wnioski, model k-średnich źle rozdziela dane. Zobaczmy jeszcze jak to wygląda z danymi testowymi.",
   "id": "a7980fba942a0b1c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![wykres k-średnich danych testowych](ksrednich_dane_testowe.png)",
   "id": "fb39eeb5f79c05a8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dane testowe oczywiście też niewpełni zgadzają się z rzeczywistością ze względu na specyfikację uczenia nienadzorowanego. Jednakże w tym przypadku śmiało możemy określić, iż model testowy jest o wiele bliżej prawdy, widać znacznie mniejszą ilość jakości 7, lecz modelowi temu dalej daleko do perfekcji.",
   "id": "927a63fb6c7b74fb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Podsumowanie\n",
    "Ze względu na specyfikację danych, bardzo ciężko było zbudować model który by dobrze klasyfikował dane, szacował ich wartości końcowe, natomiast zarówno model XGBoost w regresji i Random Forest w klasyfikacji, przy daniu sobie współczynnika błędu ±1 miał bardzo wysoką trafność. Sytuacja najgorzej wyglądała w przypadku podziału na grupy. Algorytm K-Średnich nie był w stanie poprawnie porozdzielać grupy, co skutkowało znacznym zawyżaniem jakości 7."
   ],
   "id": "b9157a36453f45bc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
